2025-08-04 02:38:45,697 - INFO - Loading efficientnet features from embeddings/efficientnet_embeddings_20250804_012258
2025-08-04 02:38:45,704 - INFO - ✅ Features loaded successfully
2025-08-04 02:38:45,705 - INFO - 📊 Train features: (771, 1280)
2025-08-04 02:38:45,705 - INFO - 📊 Test features: (387, 1280)
2025-08-04 02:38:45,705 - INFO - 📊 Feature dimension: 1280
2025-08-04 02:38:45,705 - INFO - 🚀 Starting MEDIUM hyperparameter XGBoost training...
2025-08-04 02:38:45,705 - INFO - 🔧 MEDIUM hyperparameter tuning...
2025-08-04 02:38:45,705 - INFO - 📊 Total parameter combinations: 16
2025-08-04 02:38:45,705 - INFO - 🔄 Cross-validation folds: 3
2025-08-04 02:38:45,705 - INFO - ⏱️  Estimated time: 8.0 - 24.0 minutes
2025-08-04 02:38:45,705 - INFO - 🚀 Starting hyperparameter search...
2025-08-04 02:40:47,320 - INFO - ✅ Hyperparameter search completed!
2025-08-04 02:40:47,320 - INFO - ⏱️  Total training time: 0:02:01.614290
2025-08-04 02:40:47,320 - INFO - 🏆 Best parameters found:
2025-08-04 02:40:47,320 - INFO -    colsample_bytree: 0.8
2025-08-04 02:40:47,320 - INFO -    learning_rate: 0.2
2025-08-04 02:40:47,320 - INFO -    max_depth: 6
2025-08-04 02:40:47,320 - INFO -    n_estimators: 200
2025-08-04 02:40:47,320 - INFO -    reg_alpha: 0
2025-08-04 02:40:47,321 - INFO -    reg_lambda: 1
2025-08-04 02:40:47,321 - INFO -    subsample: 1.0
2025-08-04 02:40:47,321 - INFO - 🏆 Best CV F1 score: 0.4412
2025-08-04 02:40:47,337 - INFO - 🔝 Top parameter combinations:
2025-08-04 02:40:47,337 - INFO -    1. F1: 0.4412 (±0.0447) - {'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 200, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 1.0}
2025-08-04 02:40:47,337 - INFO -    2. F1: 0.4395 (±0.0406) - {'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 0.8}
2025-08-04 02:40:47,338 - INFO -    3. F1: 0.4344 (±0.0408) - {'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 100, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 1.0}
2025-08-04 02:40:47,338 - INFO -    4. F1: 0.4287 (±0.0471) - {'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 200, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 0.8}
2025-08-04 02:40:47,338 - INFO -    5. F1: 0.4272 (±0.0398) - {'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 100, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 0.8}
2025-08-04 02:40:47,338 - INFO - 📊 Evaluating best model on training and test sets...
2025-08-04 02:40:47,338 - INFO - 🔍 Evaluating on train set (771 samples)...
2025-08-04 02:40:47,338 - INFO -    Making predictions...
2025-08-04 02:40:47,342 - INFO -    Calculating probabilities...
2025-08-04 02:40:47,346 - INFO -    Computing metrics...
2025-08-04 02:40:47,354 - INFO - 📊 TRAIN RESULTS:
2025-08-04 02:40:47,354 - INFO -    📈 Accuracy:  1.0000
2025-08-04 02:40:47,354 - INFO -    📈 Precision: 1.0000
2025-08-04 02:40:47,355 - INFO -    📈 Recall:    1.0000
2025-08-04 02:40:47,355 - INFO -    📈 F1 Score:  1.0000
2025-08-04 02:40:47,355 - INFO -    📈 ROC AUC:   1.0000
2025-08-04 02:40:47,355 - INFO -    📊 True distribution: {np.float32(0.0): np.int64(425), np.float32(1.0): np.int64(346)}
2025-08-04 02:40:47,355 - INFO -    📊 Pred distribution: {np.int64(0): np.int64(425), np.int64(1): np.int64(346)}
2025-08-04 02:40:47,355 - INFO - 🔍 Evaluating on test set (387 samples)...
2025-08-04 02:40:47,355 - INFO -    Making predictions...
2025-08-04 02:40:47,357 - INFO -    Calculating probabilities...
2025-08-04 02:40:47,359 - INFO -    Computing metrics...
2025-08-04 02:40:47,367 - INFO - 📊 TEST RESULTS:
2025-08-04 02:40:47,368 - INFO -    📈 Accuracy:  0.7726
2025-08-04 02:40:47,368 - INFO -    📈 Precision: 0.8095
2025-08-04 02:40:47,368 - INFO -    📈 Recall:    0.7083
2025-08-04 02:40:47,368 - INFO -    📈 F1 Score:  0.7556
2025-08-04 02:40:47,368 - INFO -    📈 ROC AUC:   0.8253
2025-08-04 02:40:47,368 - INFO -    📊 True distribution: {np.float32(0.0): np.int64(195), np.float32(1.0): np.int64(192)}
2025-08-04 02:40:47,368 - INFO -    📊 Pred distribution: {np.int64(0): np.int64(219), np.int64(1): np.int64(168)}
2025-08-04 02:40:47,378 - INFO - 📄 Performance metrics saved to: experiments/medium_xgboost_efficientnet_20250804_023845/performance_metrics.txt
2025-08-04 02:40:47,378 - INFO - 💾 Model saved to: experiments/medium_xgboost_efficientnet_20250804_023845/best_model.pkl
2025-08-04 02:40:47,379 - INFO - 💾 Results saved to: experiments/medium_xgboost_efficientnet_20250804_023845/results.json
2025-08-04 02:40:47,379 - INFO - 💾 CV results saved to: experiments/medium_xgboost_efficientnet_20250804_023845/cv_results.csv
2025-08-04 02:40:47,379 - INFO - 📊 Creating visualization plots...
2025-08-04 02:40:47,380 - INFO -    📈 Creating feature importance plot...
2025-08-04 02:40:47,997 - INFO -    📈 Creating confusion matrix...
2025-08-04 02:40:48,379 - INFO -    📈 Creating ROC curve...
2025-08-04 02:40:48,720 - INFO -    📈 Creating hyperparameter search visualization...
2025-08-04 02:40:48,782 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-08-04 02:40:48,783 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-08-04 02:40:48,793 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-08-04 02:40:48,793 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-08-04 02:40:49,532 - INFO - ✅ All 4 plots created successfully
2025-08-04 02:40:49,532 - INFO - 📁 Plots saved to: experiments/medium_xgboost_efficientnet_20250804_023845/plots
